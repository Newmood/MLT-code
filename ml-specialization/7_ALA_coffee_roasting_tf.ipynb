{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will go through the coffee roasting problem discussed in the course. First implementing it using tensorflow then only numpy."
      ],
      "metadata": {
        "id": "WyUlf2Jsx5hQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Br-gszXiHOWc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def coffee_roasting_dataset():\n",
        "    rng = np.random.default_rng(42)\n",
        "    X = rng.random(400).reshape(-1,2)   # X will be 2-d array of shape (200,2)\n",
        "    X[:,0] = X[:,0] * (285-150) + 150   # scaling to range (150,285) - temparature in C\n",
        "    X[:,1] = X[:,1] * 5 + 11            # scaling to range (11,16) - time in mins\n",
        "    Y = np.zeros(len(X))\n",
        "\n",
        "    i=0\n",
        "    for temp,time in X:\n",
        "        y = -3/(260-175)*temp + 21      # (175-260,12-15) is good temp,time range, y=mx+c line defining upper bounds\n",
        "        if (temp > 175 and temp < 260 and time > 12 and time < 15 and time<=y ):\n",
        "            Y[i] = 1\n",
        "        else:\n",
        "            Y[i] = 0\n",
        "        i += 1\n",
        "\n",
        "    return (X, Y.reshape(-1,1))"
      ],
      "metadata": {
        "id": "Omir3l_1puiN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code cell, the coffee data we will work with is generated.\n",
        "1. First we take 400 random numbers between 0 and 1, reshape it into 200 samples with 2 features, that wil be temparature and time duration.\n",
        "2. The random numbers are scaled to take values between desired range for temparature and time duration.\n",
        "3. We find the line that will help us define the upper bound by solving the following equations: $$ 12 = 260m+c \\\\ 15= 175m+c $$\n",
        "4. We check if temp and time are in desired range, and put target labels on it."
      ],
      "metadata": {
        "id": "fuNLnaVB607u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalisation(X):\n",
        "    norm1 = tf.keras.layers.Normalization(axis=1)\n",
        "    norm1.adapt(X)\n",
        "    Xnorm = norm1(X)\n",
        "    return Xnorm"
      ],
      "metadata": {
        "id": "A5QWCi1_59ai"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization_summary(X,Xn):\n",
        "\n",
        "    result = f\"\"\"\n",
        "    Before normalisation: \\n\n",
        "    Minimum temparature: {np.min(X[:,0]):.2f}, Maximum temparature: {np.max(X[:,0]):.2f} \\n\n",
        "    Minimum duration: {np.min(X[:,1]):.2f}, Maximum duration: {np.max(X[:,1]):.2f}\\n\n",
        "\n",
        "    After normalisation: \\n\n",
        "    Minimum temparature: {np.min(Xn[:,0]):.2f}, Maximum temparature: {np.max(Xn[:,0]):.2f} \\n\n",
        "    Minimum duration: {np.min(Xn[:,1]):.2f}, Maximum duration: {np.max(Xn[:,1]):.2f}\\n\"\"\"\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "MYcATi8919rP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "MZHSrxSYKUxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = coffee_roasting_dataset()\n",
        "print(X.shape, Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5e9aFejGjpf",
        "outputId": "36fba6f3-950c-40bd-fd41-7bd83b23b356"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 2) (200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xn = normalisation(X)\n",
        "print(normalization_summary(X,Xn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMbZMC8LGjUj",
        "outputId": "5fc59bd6-cf5a-4930-ccd2-cef7731baf61"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Before normalisation: \n",
            "\n",
            "    Minimum temparature: 151.66, Maximum temparature: 282.24 \n",
            "\n",
            "    Minimum duration: 11.04, Maximum duration: 15.96\n",
            "\n",
            "\n",
            "    After normalisation: \n",
            "\n",
            "    Minimum temparature: -1.65, Maximum temparature: 1.74 \n",
            "\n",
            "    Minimum duration: -1.77, Maximum duration: 1.70\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# below we will tile to increase training sample size\n",
        "Xt = np.tile(Xn,(1000,1))\n",
        "Yt= np.tile(Y,(1000,1))\n",
        "print(Xt.shape, Yt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxk170Lk1GOZ",
        "outputId": "7ccfa55d-0521-4fd8-c483-41ca31bb145f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200000, 2) (200000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow implementation"
      ],
      "metadata": {
        "id": "Z3kOwAoLKYK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1234)\n",
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(2,)),\n",
        "        Dense(3, activation='sigmoid', name = 'layer1'),\n",
        "        Dense(1, activation='sigmoid', name = 'layer2')\n",
        "     ]\n",
        ")"
      ],
      "metadata": {
        "id": "YAnZ2DkGKM6H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CfYhnwzKpgT",
        "outputId": "ad012a3a-ccce-473c-9147-74b905b51661"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer1 (Dense)              (None, 3)                 9         \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13 (52.00 Byte)\n",
            "Trainable params: 13 (52.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following weights are isntantiated in model\n",
        "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
        "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
        "print(f\"W1{W1.shape}:\\n\", W1, f\"\\n b1{b1.shape}:\", b1)\n",
        "print(f\"W2{W2.shape}:\\n\", W2, f\"\\n b2{b2.shape}:\", b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MitszKSIKucg",
        "outputId": "996c458a-f1ae-4dd2-8dd6-2fc45e531670"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1(2, 3):\n",
            " [[-0.01135743  0.17004311 -0.9350109 ]\n",
            " [-0.51178366  0.665051    0.06859589]] \n",
            " b1(3,): [0. 0. 0.]\n",
            "W2(3, 1):\n",
            " [[-0.89698267]\n",
            " [-0.83132803]\n",
            " [ 0.02676749]] \n",
            " b2(1,): [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        ")\n",
        "\n",
        "model.fit(Xt,Yt,epochs=10,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7Goyo-9LIOT",
        "outputId": "d8173de9-4004-4b88-fed9-4bf9494a0883"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.1117\n",
            "Epoch 2/10\n",
            "6250/6250 [==============================] - 11s 2ms/step - loss: 0.0129\n",
            "Epoch 3/10\n",
            "6250/6250 [==============================] - 11s 2ms/step - loss: 0.0064\n",
            "Epoch 4/10\n",
            "6250/6250 [==============================] - 12s 2ms/step - loss: 0.0041\n",
            "Epoch 5/10\n",
            "6250/6250 [==============================] - 12s 2ms/step - loss: 0.0029\n",
            "Epoch 6/10\n",
            "6250/6250 [==============================] - 12s 2ms/step - loss: 0.0022\n",
            "Epoch 7/10\n",
            "6250/6250 [==============================] - 12s 2ms/step - loss: 0.0016\n",
            "Epoch 8/10\n",
            "6250/6250 [==============================] - 12s 2ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "6250/6250 [==============================] - 11s 2ms/step - loss: 9.4349e-04\n",
            "Epoch 10/10\n",
            "6250/6250 [==============================] - 12s 2ms/step - loss: 7.3493e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a9bf57a6980>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating weights after model fit\n",
        "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
        "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
        "print(\"W1:\\n\", W1, \"\\n b1:\", b1)\n",
        "print(\"W2:\\n\", W2, \"\\n b2:\", b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY3AUo7uLocf",
        "outputId": "c68e487a-7a6e-4970-8104-753b03361d28"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1:\n",
            " [[ -0.4007091  18.571972  -23.231821 ]\n",
            " [-11.409808   19.832968   -0.4668565]] \n",
            " b1: [-12.909796    1.5053629 -25.76176  ]\n",
            "W2:\n",
            " [[-46.954582]\n",
            " [-62.214245]\n",
            " [-58.76812 ]] \n",
            " b2: [21.383799]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the above values of weights and bias for testing our numpy implementaiton."
      ],
      "metadata": {
        "id": "ZdBvO56Rv5gF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions:"
      ],
      "metadata": {
        "id": "7B-1gxFIZVwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([\n",
        "    [200,13.9],  # postive example\n",
        "    [200,17]])   # negative example\n",
        "X_testn = normalisation(X_test)\n",
        "predictions = model.predict(X_testn)\n",
        "print(\"Predictions = \\n\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ-tAZjWOmLi",
        "outputId": "d97758a3-a8ce-4a79-cd7e-cdaee0e72845"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 90ms/step\n",
            "Predictions = \n",
            " [[9.9999732e-01]\n",
            " [1.8516688e-18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = (predictions >= 0.5).astype(int)\n",
        "print(f\"decisions = \\n{yhat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_fCuVcLU8BO",
        "outputId": "c901853c-5068-410c-9e09-3e220397b53a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decisions = \n",
            "[[1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numpy implementation"
      ],
      "metadata": {
        "id": "xnfMbNZ-hpjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the same code for dataset generation and normalisation."
      ],
      "metadata": {
        "id": "hFwcI8Awq4fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def g(z):\n",
        "    sig = 1/(1 + np.exp(-z))\n",
        "    return sig"
      ],
      "metadata": {
        "id": "idDkSb2grUAi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_dense(a_in, W, b, g):\n",
        "    \"\"\"\n",
        "    Computes a dense layer\n",
        "    Args:\n",
        "      a_in (ndarray (n, )) : Data, 1 example\n",
        "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
        "      b    (ndarray (j, )) : bias vector, j units\n",
        "      g    activation function (e.g. sigmoid, relu..)\n",
        "    Returns\n",
        "      a_out (ndarray (j,))  : j units\n",
        "    \"\"\"\n",
        "    units = W.shape[1]        # number of neurons (units)\n",
        "    a_out = np.zeros(units)\n",
        "    for j in range(units):\n",
        "        w = W[:,j]            # column-wise, neuron by neuron\n",
        "        z = np.dot(w, a_in) + b[j]\n",
        "        a_out[j] = g(z)       # sigmoid activation\n",
        "    return(a_out)"
      ],
      "metadata": {
        "id": "M_vw8QuMh2Lv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_sequential(x, W1, b1, W2, b2):\n",
        "    a1 = my_dense(x,  W1, b1, g)\n",
        "    a2 = my_dense(a1, W2, b2, g)\n",
        "    return(a2)"
      ],
      "metadata": {
        "id": "mwxCH0-hteXf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_predict(X, W1, b1, W2, b2):\n",
        "    m = X.shape[0]\n",
        "    p = np.zeros((m,1))\n",
        "    for i in range(m):\n",
        "        p[i,0] = my_sequential(X[i], W1, b1, W2, b2)\n",
        "    return p"
      ],
      "metadata": {
        "id": "ZgaNiNActflj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the numpy code\n",
        "We will use the testing set above and model weights to check if numpy implementation is correct. It should give the same value as predicted using tf."
      ],
      "metadata": {
        "id": "zl9l5u_ywEHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([\n",
        "    [200,13.9],  # postive example\n",
        "    [200,17]])   # negative example\n",
        "X_testn = normalisation(X_test)"
      ],
      "metadata": {
        "id": "jvdY_BKaER_k"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_predictions = my_predict(X_testn,W1,b1,W2,b2)\n",
        "print(\"Predictions = \\n\", my_predictions)\n",
        "\n",
        "yhat = (my_predictions >= 0.5).astype(int)\n",
        "print(f\"decisions = \\n{yhat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GUFylJSvwK8",
        "outputId": "4281a1dd-5274-4008-d8c1-90e6c8c196bd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions = \n",
            " [[9.99997288e-01]\n",
            " [1.85166542e-18]]\n",
            "decisions = \n",
            "[[1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions are the same."
      ],
      "metadata": {
        "id": "RhYuzEJZFlR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numpy Vectorized implementation"
      ],
      "metadata": {
        "id": "4Xm79WRFxBNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_vec_dense(a_in, W, b, g):\n",
        "    \"\"\"\n",
        "    Computes a dense layer faster, because this is vectorized.\n",
        "    Args:\n",
        "      a_in (ndarray (n, )) : Data, 1 example\n",
        "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
        "      b    (ndarray (j, )) : bias vector, j units\n",
        "      g    activation function (e.g. sigmoid, relu..)\n",
        "    Returns\n",
        "      a_out (ndarray (j,))  : j units\n",
        "    \"\"\"\n",
        "    z = a_in@W +b\n",
        "    a_out = g(z)\n",
        "    return a_out"
      ],
      "metadata": {
        "id": "vGeeT88mxJCb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following functions are same except they use vectorized dense (``my_vc_dense``) now."
      ],
      "metadata": {
        "id": "rcz96g8OyxpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_vec_sequential(x, W1, b1, W2, b2):\n",
        "    a1 = my_vec_dense(x,  W1, b1, g)\n",
        "    a2 = my_vec_dense(a1, W2, b2, g)\n",
        "    return(a2)"
      ],
      "metadata": {
        "id": "XDqSKw9FzBOu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_vec_predict(X, W1, b1, W2, b2):\n",
        "    m = X.shape[0]\n",
        "    p = np.zeros((m,1))\n",
        "    for i in range(m):\n",
        "        p[i,0] = my_vec_sequential(X[i], W1, b1, W2, b2)\n",
        "    return p"
      ],
      "metadata": {
        "id": "HAB8eQmd7sn8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will test the vectorized code"
      ],
      "metadata": {
        "id": "Nkc1adKg8EFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_testn.numpy() # converting to numpy array is not necessary here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Pirfu7FKjn",
        "outputId": "583c9955-7df7-4b62-d0d9-49fcc307cf18"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -1.],\n",
              "       [ 0.,  1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_vec_predictions = my_vec_sequential(X_testn.numpy(), W1, b1, W2, b2)\n",
        "print(\"Predictions = \\n\", my_vec_predictions)\n",
        "\n",
        "yhat = (my_vec_predictions >= 0.5).astype(int)\n",
        "print(f\"decisions = \\n{yhat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gXmAFCq7yZM",
        "outputId": "065918fe-1e2b-44aa-bcb5-3f2f514dc36d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions = \n",
            " [[9.9999726e-01]\n",
            " [1.8516690e-18]]\n",
            "decisions = \n",
            "[[1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J54n2OdQHl9w"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}